{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络的学习\n",
    "\n",
    "神经网络的特征就是从数据中学习。由数据决定权重参数的值。\n",
    "    \n",
    "> 对于线性可分问题，比如感知机可以利用数据自动学习。根据 **感知机收敛定理**，通过有限次数的学习，线性可分问题是可解的。但是，非线性可分问题是无法通过自动学习来解决。\n",
    "\n",
    "### 数据驱动\n",
    "\n",
    "数据是机器学习的核心。**特征量**，从输入的数据中准确地提取本质数据的转换器。机器学习方法中，由机器从收集的数据中找出规律性，与人工从零开始想出想法相比，这种方法更搞笑，大大减少了人工量。针对不同的问题，必须使用不同的特征量，才能得到更好的结果，所以即使使用特征量和机器学习的方法，也需要针对不同的问题人工考虑不同的特征量。\n",
    "\n",
    "如下图，神经网络直接学习图像本身。在第二个方法中，利用特征量和机器学习的方法中，特征量仍然是人工设计的。而在神经网络中，连图像包含的重要特征量都是机器学习得来的。\n",
    "\n",
    "![人工介入到机器学习](./img/neural_network_learning-1.png)\n",
    "从人工设计规则转变为由机器从数据中学习：没有人为介入的方块灰色表示\n",
    "\n",
    "> 深度学习有时也被称为是端到端的学习（end-to-end machine learning）。这里所说的端到端指的是从一端到另一端的意思，就是从原始数据（输入）获得目标结果（输出）的意思。\n",
    "\n",
    "神经网络的优点：对所有的问题都可以用同样的流程来解决。比如不管是识别数字5，还是识别狗狗，识别人脸，神经网络都是通过不停地学习所提供的数据，尝试发现待求解的问题模式。也就是说与待求解的问题无关，神经网络可以把数据直接作为原始数据，进行“端对端”的学习。\n",
    "\n",
    "### 训练集和测试集\n",
    "\n",
    "机器学习中，一般先使用训练集来学习得到最优的参数，然后使用测试集数据来评价训练结果得到模型的实际能力。为了正确评价模型的**泛化能力**，必须划分训练集和测试集。训练数据也被称为**监督数据**。\n",
    "\n",
    "### 损失函数\n",
    "\n",
    "损失函数是表示神经网络性能的“恶劣程度”的指标，即当前神经网络对监督数据多大程度上不拟合，在多大程度上不一致。在神经网络学习中，一般使用**均方误差**和**交叉熵**作为损失函数。\n",
    "\n",
    "#### 均方误差\n",
    "\n",
    "公式：\n",
    "![均方误差](./img/mean_squared_error.png)\n",
    "y<sub>k</sub> 表示神经网络的输出，t<sub>k</sub> 表示监督数据，k表示数据的维度。\n",
    "\n",
    "均方误差会计算神经网络的输出和正确解监督数据各个元素的差的平方，再求总和。python实现如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09750000000000003\n",
      "0.5975\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_squared_error(y,t):\n",
    "    return 0.5*np.sum((y-t)**2)\n",
    "\n",
    "\n",
    "# 手写数字识别 y 为输出 0-9 的数字的概率\n",
    "# eg1:  设置 2 为正确解\n",
    "t  = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "\n",
    "# 均方误差的结果：\n",
    "ret = mean_squared_error(np.array(y),np.array(t))\n",
    "print(ret)\n",
    "\n",
    "# eg2: 设置 7 为正确解\n",
    "t1 = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "\n",
    "ret2 = mean_squared_error(np.array(y),np.array(t1))\n",
    "print(ret2)\n",
    "\n",
    "# 又结果可知：ret 的损失函数的值更小，和监督数据之间的误差更小。也就是说均方误差显示第一个例子的输出结果和监督数据更吻合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉熵误差\n",
    "\n",
    "除了均方误差，**交叉熵误差**也经常被用作损失函数。\n",
    "![交叉熵误差](./img/cross_entropy_error.png)\n",
    "这里，log表示以e为底数的自然对数（log<sub>e</sub>），y<sub>k</sub> 是神经网络的输出，t<sub>k</sub>是神经网络的正确解标签。并且t<sub>k</sub>中只有正确解标签的索引为1，其他均为0（one-hot）表示，上式实际上只计算对应正解标签的输出的自然对数。\n",
    "> 比如正确解为2，对应的神经网络的输出是0.6，则交叉熵误差为 -log0.6 = 0.51；若 2 对应的输出是0.1，则交叉熵误差为 -log0.1 = 2.30。\n",
    "\n",
    "***交叉熵误差的值是由正确解标签所对应的输出结果决定的。***\n",
    "\n",
    "#### 自然对数应的函数图像："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD8CAYAAABq6S8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAXpUlEQVR4nO3de3zU9Z3v8deHhHBLIAQI4ZJwEUigXKKGi1ovKHa9rZ5atdpSVLD0cuzjbLe7PbZ2bXfdfXSP3Z6es9vttlSRrdZa3Uetl7anlj6gtiBCKBe5BblfIiFcEsIl98/5Y0aKNpAJM8nMN/N+Ph55mJn5+ZvP18m8H1+/8/l9x9wdEREJV49kFyAiIvFRkIuIBE5BLiISOAW5iEjgFOQiIoFTkIuIBC4hQW5mN5lZhZntMLNHEnFOERGJjcXbR25mGcB24EbgALAGuM/dt8RfnoiItCcRM/IZwA533+XujcDzwB0JOK+IiMQgMwHnGAHsP+f2AWDmBw8ys4XAQoB+/fpdXlJSkoCnFpHO5kBjUyv1zS3UN7VQH/29sbn17DEG9OqZQe/MHvTumUHvnj3olZlBVqY+hkuktWvXHnH3IR+8PxFBbm3c92frNe6+CFgEUFZW5uXl5Ql4ahFJlNZW52DNGSoO1VFRVUfFoTq2V9Wxs/okTS2Rt3RPg/GD+1E8NIcJQ3MoLoj8c/SgvmRmKLQ7m5ntbev+RAT5AaDwnNsjgcoEnFdEOoG7U13X8L6wrqg6yTtVdZxubDl73IjcPhQX5HBdcT7FBdlMGJrDJUOy6d0zI4nVS1sSEeRrgPFmNgY4CNwLfCIB5xWRONWebooEdlUd26Mz7e1VddScbjp7zODsXhQXZPPx6YWRmXZBDuPzs8np3TOJlUtHxB3k7t5sZg8DvwYygMXuvjnuykSkQ2rPNLFhfw3roz+bK2upOtFw9vGcXplMKMjh5snDKB6azYSCHIqH5jAou1cSq5ZESMSMHHf/JfDLRJxLRNrX1NJKxaE61u2vYf2+GtbtP86u6lMAmMElQ7K56pLBkTXsaGAPG9Abs7Y+0pLQJSTIRaTzuDuVtfWRwN53nPX7a9hUWUt9U6RrZHB2FqWFudx56QhKCwcytXAA/bUsklYU5CIp5mRDMxv310Rm29Gf6rrIEklWZg8mD+/PJ2aM4tKiXEoLcxk5sI9m2mlOQS6SRC2tzvaqukhg74uE9vbDdbx3wfXYwf24etxgSqOhXVLQX73Z8mcU5CJdqOpEPeuigb1u33HePlh7tuUvt29PSgtzuXlKAaWFkeDO7ZuV5IolBApykU5yprGFtw/Wnl3XXr+/hndr6wHomWFMGtafuy8fyaVFAyktzGXUoL5aIpGLoiAXSYDWVmdn9ck/rWvvq6Giqo6W1sgaSVFeX6aPzovMtItymTSsvy6skYRRkItchCMnG86uaa/fX8OG/TXUNTQDkNM7k9LCXD4/8ZKzSyTq1ZbOpCAXaUd9UwubK0+cXddev7+GA8fPAJDRwygpyOH20uFnl0jGDu5Hjx5aIpGuoyAXOYe7s/vIqbMz7fX7a9j67omzm0aNyO1DaWEu918xmtKiXCYPH0CfLC2RSHIpyCXtHT5Rz/Lt1fyuopoVO4+c3YekX1YGU0fm8tDVYyktzOXSwlzy+/dOcrUif05BLmmnpdVZv7+G5RWHWVZxmE0HTwAwtH8vbpw4lLLRAyktHMi4/GwytEQiAVCQS1o4erKBN96pZtm2at54p5qa001k9DAuLxrIl28qZnZxPiUFOWr/kyApyKVbam11NlXWsmxbNcsqDrPhQA3ukX1JbigZyuySIVw9bggD+mpPEgmfgly6jdrTTZFZd8Vh3thezZGTjZhBaWEuX5wzgdnF+XxoeH91lEi3oyCXYLk7W949wfKKapZXHGbt3uO0euRS92snDGF2cT7XTBhCXj9d5i7dm4JcglJX38SKHUdYtq2a5dsPn/3ihCkjBvDw7HFcV5LPtJG5+pBS0oqCXFKau/PO4ZMs2xbpMCnfc5zmViendybXjB/CdcVDuLZ4CPk5aguU9KUgl5RzurGZlTuOsqziMMsrqjlYE7mKsqQgh09fM5bZxflcWpRLT31ruwigIJcU8N7VlMuia91v7TpGY0sr/bIyuGrcYB6+fhzXFQ9h2IA+yS5VJCUpyCUp6ptaeHPXUX5XEeky2Xv0NADj8rO5/8pRzC7Op2x0nr5EQSQGCnLpMvuOnmb59sMs23aYlTuP0tDcSu+ePbjyksE89OExXFecT2Fe32SXKRIcBbl0mobmFtbsPs6y6KXw733L+6hBfblvRhGzS/KZOSZP+3KLxElBLglVWXOG5dHlkhU7jnC6sYWszB7MHJPH3JmjmF2Sz5jB/ZJdpki3oiCXuLg75XuPs3RrFcu3VVNRVQdEtnu987IRzC7O54pLBtE3S39qIp1F7y65KPVNLfx83UEWr9jN9qqTZPYwpo/O46u3lDC7OJ9x+dnagEqkiyjIpUOqTtTz7Kq9/PitfRw71cjEYf154q6p3Dy5gJze2oBKJBkU5BKTtw/UsnjFbl7bWElzqzNn4lDmXzWGWWPzNPMWSTIFuZxXc0srv9lSxeIVu1mz5zj9sjKYO2sUD1w5mlGD9IGlSKpQkMufqT3TxAtr9rNk5R4O1pyhMK8Pf3fbJO4uG0l/LZ+IpBwFuZy1+8gplqzYzYtrD3C6sYUZY/L4u9smceOkodpNUCSFKcjTnLvz5s6jLF6xm99uO0xmD+Mvpw1n/lVjmDxiQLLLE5EYKMjTVH1TC6+sr2Txit1sO1THoH5ZfOH68cydVaQtYUUCoyBPM4fPaR88eqqRkoIcnrhrKrdPG65L5UUCpSBPE5sORtoHX90QaR+8oSSf+VeN4YpLBql9UCRwCvJurKXVz7YPrt59jL5ZGXxy5ijuv3K09jsR6UbiCnIzuxv4BjARmOHu5YkoSuJzov5P7YMHjp9hRG4fvnbrRO4uK2RAH7UPinQ38c7INwF3Aj9IQC0Sp71HT/H0ij28WL6fU40tzBidx9dunciciUPJ1NeiiXRbcQW5u28FtMaaRO7Oql3HWLxiN0u3VpHZw7htaqR9cMpItQ+KpIMuWyM3s4XAQoCioqKuetpuq76phVc3VLJ4xR62vnuCvH5ZPDx7HHNnjWJof7UPiqSTdoPczJYCBW089Ki7vxzrE7n7ImARQFlZmcdcobxPdV1DtH1wL0dONlI8NIf/9bEp3FE6Qu2DImmq3SB39zldUYhc2ObKWhb/YQ+vbqiksaU10j744TFcqfZBkbSn9sMU1tLq/HZrpH1w1a5I++B9Mwq5/8rRjB2SnezyRCRFxNt++FHg34AhwC/MbL27/0VCKktjdfVNvFh+gCUr97Dv2GlG5Pbhq7eU8PGyIgb0VfugiLxfvF0rLwEvJaiWtLfv6GmWrNzDC+X7OdnQTNmogTxycwkfmaT2QRE5Py2tJJm789buYyz+w25+s7WKDDNumzqMB68aw7TC3GSXJyIBUJAnSUNzC69teJfFK3azufIEA/v25L9fN45PXaH2QRHpGAV5Ehw4fpp5i1ezq/oU4/Oz+eadU/hvpSPok6X2QRHpOAV5F9tVfZK5T77FyYZmnrq/jOtL8tU+KCJxUZB3oS2VJ5i3+C0Anl94BZOG909yRSLSHSjIu8javcd58OnV9OuVybMPzeQS9YGLSIIoyLvAH945wsJnysnP6cWzD81k5MC+yS5JRLoRBXkne33zIR5+bh1jh/TjRwtm6PswRSThFOSd6KV1B/ibFzcyZcQAljw4ndy+WckuSUS6IQV5J3lm1V4ee3kTV4wdxKJ5ZWT30n9qEekcSpdO8L3lO3ji/1UwZ2I+3/3EZdpeVkQ6lYI8gdydJ35dwX8s38nt04bz7Xum0VN7pIhIJ1OQJ0hrq/P1VzbzzKq9fGJmEY/fMZmMHrrQR0Q6n4I8AZpbWvnyf23kZ+sO8plrx/LITSW6WlNEuoyCPE4NzS184bl1vL6lir/9i2I+f90lCnER6VIK8jicbmxm4Y/W8ocdR/j72z/E/VeOTnZJIpKGFOQXqfZMEw8+vZr1+2v4l7uncdflI5NdkoikKQX5RThysoFPPbWaHYfr+N4nL+OmycOSXZKIpDEFeQdV1pxh7pNvUVl7hqfun841E4YkuyQRSXMK8g7YfeQUc598ixNnmnh2wUzKRucluyQREQV5rLYdOsHcJ1fT6s5PFs5i8ogByS5JRARQkMdk3b7jPPD0Gvr0zODZh2YyLj8n2SWJiJylIG/Hyp1HeOg/yxmS04tnF8ykME97iYtIalGQX8DSLVV8/rk/MnpQX55dMJN8fbu9iKQgBfl5vLz+IF96YQMfGt6fJQ/OYGA/7SUuIqlJQd6G597ax6M/f5sZo/N46oHp2ktcRFKaEuoDfvC7nXzzV9u4viSf731Se4mLSOpTkEe5O99+fTvfXbaD26YO43/fU0pWpvYSF5HUpyAnspf4P7y2hSUr93Dv9EL+6aNTtJe4iAQj7YO8uaWVR372Nv+19gCfvnoMX71lorahFZGgpHWQNzS38FfPr+dXmw7x1zdO4AvXj1OIi0hw0jbITzc285ln1vL7d47w2G2TmP/hMckuSUTkoqRlkJ+ob2L+02v4477jPPGxqdwzvTDZJYmIXLS0C/KjJxuYt3g126vq+Lf7LuPWqdpLXETCFld/nZl9y8y2mdlGM3vJzHITVVhnOFRbzz0/eJOd1Sf54bwyhbiIdAvxNkr/Bpjs7lOB7cBX4i+pc+w9eoq7vr+SqhMN/Gj+TK4rzk92SSIiCRFXkLv76+7eHL25CkjJL66sOFTH3d9/k1MNzfzk07OYMUZfCCEi3UciL12cD/zqfA+a2UIzKzez8urq6gQ+7YVt2F/Dxxe9CcALn7mCKSP1hRAi0r20+2GnmS0FCtp46FF3fzl6zKNAM/Dj853H3RcBiwDKysr8oqrtoFW7jrJgyRrysrP48YJZFA3SXuIi0v20G+TuPudCj5vZ/cBtwA3u3iUBHYtl2w7z2WfXUpTXl2cWzKRggPYSF5HuKa72QzO7CfifwLXufjoxJcXv1Q2VfPGn65k4rD//OX8GedpLXES6sXj7yL8L9AJ+E720fZW7fzbuquLw/Op9fOWlt5k+Ko+nHigjp3fPZJYjItLp4gpydx+XqEIS4cnf7+Iff7GVaycM4ftzL6dPlvYSF5Hur1tc2enu/J+l7/B/f/sOt04Zxnc+rr3ERSR9BB/k7s7jr21l8Yrd3FM2km/eOVV7iYtIWgk6yFtana/8bCMvlB9g/lVj+NqtE+mhEBeRNBNskDc2t/LFn67nF2+/y/+4YTx/NWe89hIXkbQUZJCfaWzhcz9ey/KKar5260QeunpssksSEUma4IK8rr6JBUvKWbP3GP985xTunVGU7JJERJIqqCA/dqqRB55ezZbKE/zrvZfyl9OGJ7skEZGkCyrI//7VzVQcqmPRvMu5vmRosssREUkJQQX5Y7dN4lOzRlE2WtvQioi8J6ggH5Tdi0HZvZJdhohIStHljyIigVOQi4gETkEuIhI4BbmISOAU5CIigVOQi4gETkEuIhI4BbmISOAU5CIigVOQi4gETkEuIhI4BbmISOAU5CIigVOQi4gETkEuIhI4BbmISOAU5CIigVOQi4gETkEuIhI4BbmISOAU5CIigVOQi4gETkEuIhI4BbmISOAU5CIigYsryM3scTPbaGbrzex1MxueqMJERCQ28c7Iv+XuU929FHgNeCwBNYmISAfEFeTufuKcm/0Aj68cERHpqMx4T2Bm/wTMA2qB2Rc4biGwEKCoqCjepxURkShzv/Ak2syWAgVtPPSou798znFfAXq7+9fbe9KysjIvLy/vaK0iImnNzNa6e9kH7293Ru7uc2J8jueAXwDtBrmIiCROvF0r48+5eTuwLb5yRESko+JdI/9nMysGWoG9wGfjL0lERDoiriB3948lqhAREbk4urJTRCRwCnIRkcApyEVEAqcgFxEJnIJcRCRwCnIRkcApyEVEAqcgFxEJnIJcRCRwCnIRkcApyEVEAqcgFxEJnIJcRCRwCnIRkcApyEVEAqcgFxEJnIJcRCRwCnIRkcApyEVEAqcgFxEJnIJcRCRwCnIRkcApyEVEAqcgFxEJnIJcRCRwCnIRkcApyEVEAqcgFxEJnIJcRCRwCnIRkcApyEVEAqcgFxEJnIJcRCRwCnIRkcAlJMjN7G/MzM1scCLOJyIisYs7yM2sELgR2Bd/OSIi0lGJmJF/B/gy4Ak4l4iIdFBcQW5mtwMH3X1DDMcuNLNyMyuvrq6O52lFROQcme0dYGZLgYI2HnoU+CrwkVieyN0XAYsAysrKNHsXEUmQdoPc3ee0db+ZTQHGABvMDGAk8Eczm+HuhxJapYiInFe7QX4+7v42kP/ebTPbA5S5+5EE1CUiIjFSH7mISOAuekb+Qe4+OlHnEhGR2GlGLiISOAW5iEjgFOQiIoFTkIuIBE5BLiISOAW5iEjgFOQiIoFTkIuIBE5BLiISOAW5iEjgFOQiIoFTkIuIBE5BLiISOAW5iEjgFOQiIoFTkIuIBE5BLiISOAW5iEjgFOQiIoFTkIuIBE5BLiISOAW5iEjgFOQiIoFTkIuIBE5BLiISOAW5iEjgFOQiIoFTkIuIBE5BLiISOAW5iEjgFOQiIoFTkIuIBE5BLiISOAW5iEjgFOQiIoGLK8jN7BtmdtDM1kd/bklUYSIiEpvMBJzjO+7+Lwk4j4iIXAQtrYiIBC4RM/KHzWweUA58yd2Pt3WQmS0EFkZvnjSzigQ8d2caDBxJdhEJ0F3GARpLKuou44AwxjKqrTvN3S/4b5nZUqCgjYceBVYRGbgDjwPD3H1+fHWmBjMrd/eyZNcRr+4yDtBYUlF3GQeEPZZ2Z+TuPieWE5nZD4HX4q5IREQ6JN6ulWHn3PwosCm+ckREpKPiXSN/wsxKiSyt7AE+E3dFqWNRsgtIkO4yDtBYUlF3GQcEPJZ218hFRCS1qf1QRCRwCnIRkcCldZCb2U1mVmFmO8zskTYe/2sz22JmG83st2bWZg9nKmhvLOccd5eZuZmlbJtVLGMxs3uir81mM3uuq2uMRQx/X0VmtszM1kX/xlJ2iwszW2xmh82szYYGi/jX6Fg3mtllXV1jLGIYxyej9W80s5VmNq2ra7wo7p6WP0AGsBMYC2QBG4BJHzhmNtA3+vvngJ8mu+6LHUv0uBzgDSL9/2XJrjuO12U8sA4YGL2dn+y6L3Ici4DPRX+fBOxJdt0XGM81wGXApvM8fgvwK8CAWcBbya75Isdx5Tl/Vzen6jg++JPOM/IZwA533+XujcDzwB3nHuDuy9z9dPTmKmBkF9cYq3bHEvU48ARQ35XFdVAsY/k08O8evYrY3Q93cY2xiGUcDvSP/j4AqOzC+jrE3d8Ajl3gkDuAH3nEKiD3A+3JKaG9cbj7Sv/T1emp/J5/n3QO8hHA/nNuH4jedz4LiMw4UlG7YzGzS4FCd0/1i7ZieV0mABPMbIWZrTKzm7qsutjFMo5vAHPN7ADwS+ALXVNap+jo+ykEqfyef59E7LUSKmvjvjZ7Mc1sLlAGXNupFV28C47FzHoA3wEe6KqC4hDL65JJZHnlOiIzpt+b2WR3r+nk2joilnHcByxx92+b2RXAM9FxtHZ+eQkX8/spBGY2m0iQfzjZtcQinWfkB4DCc26PpI3/tTWzOUT2lbnd3Ru6qLaOam8sOcBkYLmZ7SGyhvlKin7gGcvrcgB42d2b3H03UEEk2FNJLONYALwA4O5vAr2JbNwUopjeTyEws6nAk8Ad7n402fXEIp2DfA0w3szGmFkWcC/wyrkHRJcjfkAkxFNxHfY9FxyLu9e6+2B3H+3uo4ms/d3u7uXJKfeC2n1dgJ8T+SAaMxtMZKllV5dW2b5YxrEPuAHAzCYSCfLqLq0ycV4B5kW7V2YBte7+brKL6igzKwJ+BnzK3bcnu55Ype3Sirs3m9nDwK+JdBgsdvfNZvYPQLm7vwJ8C8gGXjQzgH3ufnvSij6PGMcShBjH8mvgI2a2BWgB/jbVZk4xjuNLwA/N7ItEliEe8Gi7RKoxs58QWcoaHF3T/zrQE8Ddv09kjf8WYAdwGngwOZVeWAzjeAwYBHwv+p5v9gB2RNQl+iIigUvnpRURkW5BQS4iEjgFuYhI4BTkIiKBU5CLiAROQS4iEjgFuYhI4P4/X4YNxy/1zKkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "x = np.arange(0.1,1.5,0.2)\n",
    "y = np.log(x)\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.ylim(-5,0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代码实现交叉熵误差："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    delta = 1e-7 \n",
    "    # 加上一个微小值，是为了避免 出现log(0)时，np.log(0) 会变得负无穷大\n",
    "    return -np.sum(t*np.log(y+delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510825457099338\n",
      "2.302584092994546\n"
     ]
    }
   ],
   "source": [
    "# 手写数字识别 y 为输出 0-9 的数字的概率\n",
    "# eg1:  设置 2 为正确解\n",
    "t  = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "\n",
    "# 均方误差的结果：\n",
    "ret = cross_entropy_error(np.array(y),np.array(t))\n",
    "print(ret)\n",
    "\n",
    "# eg2: 设置 7 为正确解\n",
    "t1 = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "\n",
    "ret2 = cross_entropy_error(np.array(y),np.array(t1))\n",
    "print(ret2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-10,10,1)\n",
    "y = 0.02*x**2+0.1*x\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mini-batch学习\n",
    "\n",
    "机器学习使用训练数据进行学习，严格来讲就是根据训练数据计算损失函数的值，找出使该值尽可能小的参数，因此，计算损失函数时必须将所有训练数据作为对象。如果训练数据有100个的话，我们要把100个损失函数的总和作为学习指标。\n",
    "\n",
    "前面介绍的都是单个数据的损失函数，如果需要所有训练数据的损失函数总和，以交叉熵为例，公式如下：\n",
    "![mini-batch-cross-entropy-error](./img/mini_batch_cross_entropy_error.png)\n",
    "这里假设数据有N个，t<sub>nk</sub>表示第n个数据的第k个元素的值（y<sub>nk</sub>神经网络的输出，t<sub>nk</sub>是监督数据），式子实际上就是把单个损失函数扩大至N份数据，不过最要除以N正规化。通过除以N，可以求出单个数据的**平均损失函数**，通过这样的平均，可以获得和训练数据无关的统一指标，比如，即便训练数据有1000个或者10000个，也可以求得单个数据的平均损失函数。\n",
    "\n",
    "另外，如果训练数据特别大，达到百万千万级别，这种情况下对数据算损失函数是不现实的，因此我们可以从全部数据中抽取一部分数据，作为全部数据的“近似值”，神经网络的学习也是从全部数据中选取一部分数据，然后对每个mini-batch进行学习，这种学习方式称为 **mini-batch学习**。\n",
    "\n",
    "下面来编写从训练数据中随机指定个数的数据代码，以进行mini-batch学习。\n",
    "读取 MNIST 数据集\n",
    "```py\n",
    "import os,sys\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train,t_train),(x_test,t_test) = load_mnist(normalize=True,one_hot_label=True)\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "```\n",
    "上面读入的数据有60000个，数据数据是784维（28*28）的图像数据，监督数据是10维的数据，因此，上面的x_train和t_train的形状分别是（60000,784），（60000,10），那么如何从这些数据中抽取10笔数据呢？可以使用numpy的 <code style=\"color:red;\">np.random.choice() </code>,写成如下形式：\n",
    "```py\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size,batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]\n",
    "```\n",
    "<code>np.random.choice()</code> 可以从指定的数字中随机选择想要的数字，比如：<code>np.random.choice(60000,10)</code>会从0~59999中随机抽取10个数据:\n",
    "```py\n",
    "np.random.choice(60000,10)\n",
    "# array([18610, 36981, 28383, 12181, 14357, 16130, 22624, 23076,  7907, 16269])\n",
    "```\n",
    "#### mini-batch版交叉熵误差实现\n",
    "\n",
    "这里需要改良下之前单个数据的交叉熵误差的方式，让其能同时处理单个数据和多个数据情况的函数：\n",
    "\n",
    "```py\n",
    "def cross_entropy_error(y,t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1,t.size)\n",
    "        y = y.reshape(1,y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y + 1e - 7)) / batch_size\n",
    "```\n",
    "当 y 的维度为 1 时，这里需要改变下y的形状，并且当输入为mini-batch时，需要用batch的个数进行正规化，计算单个数据的平均交叉熵误差。\n",
    "\n",
    "此外，当监督数据为标签形式（非one-hot表示，而是想 “2,7”这种标签），交叉熵误差可以通过以下实现：\n",
    "```py\n",
    "def cross_entropy_error(y,t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1,t.size)\n",
    "        y = y.reshape(1,y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y[np.arange(batch_size), t] + 1e - 7)) / batch_size\n",
    "```\n",
    "\n",
    "<code>y[np.arange(batch_size), t]</code> 进行说明：当batch_size = 5 时，<code>np.arange(batch_size)</code>生成数组：[0, 1, 2, 3, 4]，因为t的标签是：[2, 7, 0, 9, 4]的形式存储的，所以 <code>y[np.arange(batch_size),t]</code> 会生成数组：[y[0, 2], y[1, 7], y[2, 0], y[3, 9], y[4, 4]]。\n",
    "\n",
    "\n",
    "#### 为何要设定损失函数\n",
    "\n",
    "在神经网络的学习中，寻找最优参数（权重和偏置）时，要寻找使损失函数的值尽可能小的参数。为了找到使损失函数的值尽可能小的地方，需要计算参数的导数（确切地讲是梯度），然后以这个导数为指引，逐步更新参数的值。\n",
    "\n",
    "### 数值微分\n",
    "\n",
    "#### 导数\n",
    "\n",
    "导数就是表示某个瞬间的变化量。式子如下：\n",
    "\n",
    "![导数](./img/derivative-1.png)\n",
    "左边的符号 df(x)/dx 表示 f(x) 关于 x 的导数，即 f(x) 关于 x 的变化程度，表示的含义是：x 的“微小变化”将导致f(x)的值在多大程度上的变化，其中表示微小变化的h无限接近于0，表示为 lim<sub>(h->0)</sub>。\n",
    "\n",
    "不好的实现：\n",
    "```py\n",
    "def numerical_diff(f, x):\n",
    "    '''\n",
    "    f: 函数 f(x)\n",
    "    x: 传给函数 f(x)的参数 x\n",
    "    '''\n",
    "    h = 10e-50\n",
    "    return (f(x + h) - f(x)) / h\n",
    "```\n",
    "\n",
    "numerical_diff 来源于 数值微分的英文 numerical differentiation，这个实现方式存在 **舍入误差**（rounding error），取 h 无限接近于 0,10e-50(有50个连续的,.0000....1)这个微小的值，所谓舍入误差，指因省略小数的精确部分的值而造成最终计算结果误差。\n",
    "\n",
    "```py\n",
    "np.float32(10e-50)\n",
    "# 0.0\n",
    "```\n",
    "\n",
    "以上代码所示：10e-50的结果是 0 导致，numerical_diff() 无法计算。\n",
    "\n",
    "另外，如下图，数值微分含有误差，为了减小这个误差，我们可以计算 f(x+h) 和 (x-h) 之间的差分，因为这种计算以 x 为中心点，计算他左右两边的差分，所以也称**中心差分**，而f(x+h) 和 x 称为**前向差分**。\n",
    "![中心差分](./img/center-differentiation.png)\n",
    "\n",
    "综上，改进数值微分：\n",
    "```py\n",
    "def numerical_diff(f, x):\n",
    "    h = 10e- 4\n",
    "    \n",
    "    return (f(x+h) - f(x -h))/ (2*h)\n",
    "```\n",
    "\n",
    "#### 数值微分的例子\n",
    "\n",
    "方程式：    y = 0.01x<sup>2</sup> + 0.1x ,求导： y'= 0.02x + 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14000000000000123\n",
      "0.200000000000089\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x\n",
    "\n",
    "def numerical_diff(f,x):\n",
    "    h = 10e-4\n",
    "    return (f(x+h) - f(x-h))/(2*h)\n",
    "\n",
    "# 求 x 分别为 2 和 5 的导数：\n",
    "# y' = 0.02*2+0.1 = 0.14\n",
    "# y' = 0.02*5+0.1 = 0.2\n",
    "\n",
    "print(numerical_diff(function_1,2)) # 0.14000000000000123\n",
    "print(numerical_diff(function_1,5)) # 0.200000000000089\n",
    "\n",
    "# 由上可知： 计算的结果 0.14 ≈ 0.14000000000000123，0.2 ≈ 0.200000000000089\n",
    "\n",
    "x = np.arange(0,20,1)\n",
    "y = function_1(x)\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 偏导数\n",
    "\n",
    "函数： $f(x_0,x_2) = x_0^2 + x_1^2$，把这里讨论的有多个变量的函数的导数称为偏导数。\n",
    "三维图如下：\n",
    "![二元二次方程](./img/3-ndim-function.png)\n",
    "\n",
    "像这样，偏导数和单变量的导数一样，都是求某个地方的斜率。不过，偏导数需要将多个变量中的某一个变量定为目标变量，并将其他变量固定为某个值。\n",
    "\n",
    "### 梯度\n",
    "\n",
    "像($\\frac{αf} {αx_0},\\frac{αf} {αx_1}$) 这样由全部变量的偏导汇总的向量称为**梯度**,梯度可以由下面来实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 10e-4 # 0.001\n",
    "    gradient = np.zeros_like(x)\n",
    "    \n",
    "    for i in range(x.size):\n",
    "        tmp_value = x[i]\n",
    "        # 计算 f(x+h) 的值\n",
    "        x[i] = tmp_value + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        # 计算 f(x-h) 的值\n",
    "        x[i] = tmp_value - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        gradient[i] = (fxh1 - fxh2) / (2*h)\n",
    "        \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9500 19500]\n"
     ]
    }
   ],
   "source": [
    "def function_1(x):\n",
    "    return np.sum(x**2)\n",
    "\n",
    "x = np.array([10,20])\n",
    "print(numerical_gradient(function_1,x))\n",
    "# [ 9500 19500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如下如所示，$f(x_0,x_1) = x_0^2 + x_1^2$ 的梯度呈现为有向向量（箭头），观察图可发现，发现梯度指向函数$f(x_0,x_1)$的最低处（最小值），就像指南针一样，所有箭头都指向同一个点。同时距离最低点越远，箭头越大。\n",
    "\n",
    "![gradient-arrow](./img/gradient_arrow.png)\n",
    "\n",
    "上图中，梯度指向了最低处，但是并非任何时候都这样，实际上梯度会指向各点处的函数值降低的方向。更严格来说，**梯度指向方向是各点处函数值减小最多的方向**。这是个非常重要的性质。\n",
    "\n",
    "#### 梯度法\n",
    "\n",
    "机器学习的主要任务是在学习时找到最优参数，同样的，神经网络必须在学习时找到最优参数（权重和偏置），这里所说的最优参数是指损失函数取最小值时的参数。但是一般而言，损失函数很复杂，参数空间庞大，我们不知道在何时能取到最小值。而通过巧妙地使用梯度来寻找函数最小值的方法就是**梯度法**。\n",
    "\n",
    "梯度表示的是各点处的函数值减小最多的方向。因此，无法保证梯度所指的方向就是函数的最小值或者真正应该前进的方向。实际上，在复杂的函数中，梯度指示的方向往往不是函数值最小值。\n",
    "\n",
    "虽然函数梯度的方向并不一定指向最小值，但沿着它的方向能最大限度地减小函数的值。因此在寻找函数最小值位置的任务中，要以梯度的信息作为线索，决定前进的方向。\n",
    "\n",
    "在梯度法中，函数的取值从当前的位置沿着梯度的方向前进一段距离，然后在新的地方重新求梯度，再沿着新的方向前进，如此反复，不断地沿着梯度的方向前进。像这样，通过不断地沿梯度方向前进，逐渐减小函数值的过程就是 **梯度法**。\n",
    "\n",
    "> 寻找最小值的梯度法称为 梯度下降法，寻找最大值的梯度法叫做 梯度上升法。一般来说，神经网络（深度学习）主要使用梯度下降法。\n",
    "\n",
    "用数学公式表示梯度法：\n",
    "\n",
    "![gradient](./img/gradient-2.png)\n",
    "式中，η表示更新量，在神经网络中表示**学习率**（learning rate）。学习率决定在一次学习中，学习多少，以及在多大程度上更新参数。\n",
    "\n",
    "上式表示更新一次的式子，这个步骤会反复执行，通过反复执行，减小函数值。\n",
    "\n",
    "学习率要事先确定某个值，比如 0.001 或者 0.0001 。一般而言，这个值过大或者过小都是无法抵达一个“最好的位置”，在神经网络中，一般会一边改变学习率的值，一边确认学习是否正确进行了。\n",
    "\n",
    "使用python来实现梯度下降法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f,init_x,l_rate=0.01,step_num=100):\n",
    "    '''梯度下降法\n",
    "    f: 需要优化的函数 f(x)\n",
    "    init_x: 初始x的值\n",
    "    l_rate: 学习率\n",
    "    step_num: 重复的次数\n",
    "    '''\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        # 对 f 求导\n",
    "        grad = numerical_gradient(f,x)        \n",
    "        x -= l_rate * grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用上面这个函数顺利的话可以求函数的极小值。\n",
    "\n",
    "例子: 用上述梯度下降法求 $f(x_0,x_1) = x_0^2 + x_1^2$的最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.005 -0.005]\n",
      "[3.33436482e+14 5.04564081e+14]\n",
      "[3.33436482e+14 5.04564081e+14]\n"
     ]
    }
   ],
   "source": [
    "def function_1(x):\n",
    "    return np.sum(x**2)\n",
    "\n",
    "x = np.array([3.0,4.0])\n",
    "\n",
    "print(gradient_descent(function_1,x,l_rate=0.1))\n",
    "# [-0.005 -0.005] 并没有取到最小值，函数的最小值是 [0, 0]\n",
    "\n",
    "# 学习率过大的例子 l_rate = 10.0\n",
    "print(gradient_descent(function_1,x,l_rate=10.0))\n",
    "# [3.33436482e+14 5.04564081e+14]\n",
    "\n",
    "# 学习率过小的例子 l_rate = 10e-10\n",
    "print(gradient_descent(function_1,x,l_rate=10e-10))\n",
    "# [3.33436482e+14 5.04564081e+14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用图来表示梯度下降法的更新过程：\n",
    "![gradient-3](./img/gradient-3.png)\n",
    "\n",
    "上述实验证明，当学习率过大时会散发很大的值，反过来学习率很小，基本上没怎么更新就结束了。也就是说设定合适的学习率是一个很重要的过程。\n",
    "\n",
    "\n",
    "#### 神经网络的梯度\n",
    "\n",
    "神经网络的学习也需要梯度，这里所说的梯度是指损失函数关于权重参数的梯度，比如有一个形状为 （2 x 3）的权重W 的神经网络，损失函数用 L 表示，此时梯度可以用  $\\frac{αf} {αW}$ 表示，用数学表示的话：\n",
    "![neural_gradient](./img/neural_gradient.png)\n",
    "\n",
    "$\\frac{\\alpha L} {\\alpha W}$ 的元素由各个元素关于W的偏导数构成。比如1行1列的元素，$\\frac{\\alpha L} {\\alpha W_{11}}$ 表示当 $w_{11}$稍微变化时，损失函数发生多大的变化。这里的重点是 $\\frac{\\alpha L} {\\alpha W}$ 的形状和 W 相同。\n",
    "\n",
    "下面以一个简单的神经网络实现求梯度的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os \n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SimpleNet(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3) # 使用高斯分布进行初始化\n",
    "        \n",
    "    def softmax(self, x):\n",
    "        if x.ndim == 2:\n",
    "            x = x.T\n",
    "            x = x - np.max(x, axis=0)\n",
    "            y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "            return y.T \n",
    "        x = x - np.max(x) # 溢出对策\n",
    "        return np.exp(x) / np.sum(np.exp(x))\n",
    "        \n",
    "    def cross_entropy_error(self, y, t):\n",
    "        if y.ndim == 1:\n",
    "            t = t.reshape(1, t.size)\n",
    "            y = y.reshape(1, y.size)\n",
    "\n",
    "        # 监督数据是one-hot-vector的情况下，转换为正确解标签的索引\n",
    "        if t.size == y.size:\n",
    "            t = t.argmax(axis=1)\n",
    "\n",
    "        batch_size = y.shape[0]\n",
    "        return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "    \n",
    "    def numerical_gradient(self, f, x):\n",
    "        h = 1e-4 # 0.0001\n",
    "        grad = np.zeros_like(x)\n",
    "\n",
    "        it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "        while not it.finished:\n",
    "            idx = it.multi_index\n",
    "            tmp_val = x[idx]\n",
    "            x[idx] = float(tmp_val) + h\n",
    "            fxh1 = f(x) # f(x+h)\n",
    "\n",
    "            x[idx] = tmp_val - h \n",
    "            fxh2 = f(x) # f(x-h)\n",
    "            grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "\n",
    "            x[idx] = tmp_val # 还原值\n",
    "            it.iternext()   \n",
    "        return grad\n",
    "\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "#         print(z)\n",
    "        y = self.softmax(z)\n",
    "#         print(y)\n",
    "        loss = self.cross_entropy_error(y, t)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.84075484  0.65305556 -1.21727999]\n",
      " [-1.0003639  -3.42380727 -0.8413993 ]]\n",
      "\n",
      "\n",
      "[-0.39587461 -2.68959321 -1.48762737]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "net = SimpleNet()\n",
    "x = np.array([0.6,0.9])\n",
    "p = net.predict(x)\n",
    "print(net.W)\n",
    "print(\"\\n\")\n",
    "print(p)\n",
    "print(np.argmax(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6822055730042766"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([0,0,1])\n",
    "net.loss(x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.41767637  0.04213962 -0.45981598]\n",
      " [ 0.62651455  0.06320942 -0.68972397]]\n"
     ]
    }
   ],
   "source": [
    "# 求梯度\n",
    "f = lambda w: net.loss(x,t)\n",
    "dw = net.numerical_gradient(f,net.W)\n",
    "print(dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
